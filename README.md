# AWQ_quantization_llama3.1instruct
From passing through a lot of hurdles from my previous project i came to know bitsandbytes are not as compatible as AWQ model so now i hardmerged with lora adaptors and then quantized the model using AWQ
